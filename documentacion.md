# üìò Documentaci√≥n Ampliada OCI Foundations (AI Focus)

> Gu√≠a enriquecida para el examen **Oracle Cloud Infrastructure AI Foundations Associate (1Z0-1122-25)**.
> Incluye conceptos clave, servicios, m√©tricas, buenas pr√°cticas y mapa tem√°tico de preguntas oficiales.

## üîç Tabla de Contenidos
1. [Resumen Ejecutivo](#-resumen-ejecutivo)
2. [Distribuci√≥n Te√≥rica](#-distribuci√≥n-te√≥rica)
3. [Panorama General OCI](#-panorama-general-de-oci)
4. [Servicios de IA en OCI](#-servicios-de-ia-en-oci)
5. [Conceptos Clave ML/DL](#-conceptos-clave-de-mldl)
6. [Trustworthy AI](#-trustworthy-ai)
7. [Infraestructura para AI](#-infraestructura-para-ai-en-oci)
8. [Dise√±o de Preguntas](#-dise√±o-de-preguntas-y-mejora-continua)
9. [Estrategias de Estudio](#-estrategias-de-estudio-sugeridas)
10. [Mapa de Preguntas](#-mapa-de-preguntas-por-tema)
11. [Extensiones Futuras](#-pr√≥ximas-extensiones)
12. [Referencias Sugeridas](#-referencias-sugeridas)
13. [Glosario](#-glosario-r√°pido)
14. [Checklist Calidad](#-checklist-de-calidad-para-nuevas-preguntas)
15. [Conclusi√≥n](#-conclusi√≥n)

---
## üöÄ Resumen Ejecutivo

| √Årea | Idea Clave | Ejemplo | Por qu√© Importa |
|------|------------|---------|-----------------|
| IA | Simula procesos cognitivos | Asistente virtual | Cubre dominio general del examen |
| ML | Aprende patrones de datos | Clasificador de spam | N√∫cleo de varias preguntas |
| DL | Redes profundas especializadas | CNN en visi√≥n | Potencia tareas complejas |
| Generative AI | Crea nuevo contenido | LLM redactando texto | Nuevo foco en fundamentos |
| Servicios OCI AI | APIs pre-entrenadas | Vision / Language / Speech | Facilitan integraci√≥n r√°pida |

### ÔøΩ Profundizaci√≥n R√°pida Servicios de IA (Resumen Ampliado)
| Servicio | Entrada principal | Salidas clave | Capacidades destacadas | Limitaciones t√≠picas | Ejemplos examen |
|----------|------------------|---------------|------------------------|---------------------|------------------|
| Vision | Imagen / Documento (PDF, JPG, PNG) | Labels, bounding boxes, texto OCR, pares clave-valor | Clasificaci√≥n documento, OCR, Detecci√≥n objetos, Extracci√≥n campos | Calidad imagen / formato soportado, iluminaci√≥n, tama√±o m√°x | Factura ‚Üí merchant/date/amount (key-value), Veh√≠culos y matr√≠culas (object detection) |
| Document Understanding | Documento estructurado / escaneado | Texto + estructura (tablas, tipo doc) | OCR + segmentaci√≥n + clasificaci√≥n tipol√≥gica | No transcribe audio, depende legibilidad | Diferenciar recibo vs curr√≠culo |
| Language | Texto | Categor√≠as, sentimiento, NER, idioma | Multi‚Äëidioma, ampliaci√≥n categor√≠as | Ambig√ºedad sem√°ntica, sarcasmo | Clasificar noticias (Politics/Tech/Sports) |
| Speech | Audio | Transcript, puntuaci√≥n confianza, marcas tiempo, SRT | Soporte formatos, filtrado lenguaje (tagging/masking/removing), normalizaci√≥n | Ruido de fondo, acentos extremos | Transcripci√≥n y normalizaci√≥n n√∫meros |
| Vector Search (DB 23ai) | Texto / Embeddings | IDs similares, puntuaci√≥n similitud | B√∫squeda sem√°ntica integrada en SQL con ONNX | Necesita embeddings consistentes | Consultas sem√°nticas vs keyword |
| Generative AI | Prompt (texto) | Texto generado, embeddings, fine-tuning parcial | T-Few, in-context, respuestas multi-turn | Riesgo alucinaciones, coste tokens | Diferencia pretraining vs supervisado |

### üîç Matriz de Tareas Vision
| Tarea | Descripci√≥n | ¬øServicio Vision? | Output t√≠pico | Ejemplo de uso |
|-------|-------------|------------------|--------------|-----------------|
| Clasificaci√≥n de Im√°genes | Asigna etiqueta global | S√≠ | Label + score | Distinguir factura vs recibo |
| Clasificaci√≥n de Documentos | Tipo documental | S√≠ | Document type | Identificar factura, curr√≠culum, contrato |
| OCR | Extraer texto crudo | S√≠ | Texto + posiciones | Extraer n√∫mero de factura |
| Key-Value Extraction | Campos estructurados (merchant, total) | S√≠ | Pares (campo, valor, confianza) | Automatizar contabilidad |
| Object Detection | Localizar m√∫ltiples objetos | S√≠ | Lista (label, bbox, score) | Veh√≠culos y matr√≠culas en parking |
| Face Recognition | Identificar rostros espec√≠ficos | No directo (requiere modelo custom) | Embeddings / labels | Control de acceso (custom) |
| Table Extraction | Reconstruir tabla estructurada | Parcial (mejor en Document Understanding) | Celdas + contenido | Importar tabla de inventario |

### üß™ Flujo Combinado Ejemplo (Factura ‚Üí Base de Datos)
| Paso | Servicio | Acci√≥n | Resultado | Valor |
|------|----------|--------|----------|-------|
| 1 | Object Storage | Almacenar PDF factura | Archivo accesible | Persistencia |
| 2 | Vision (Document Classification) | Determinar tipo factura | Tipo=Invoice | Ruteo correcto |
| 3 | Vision (OCR + Key-Value) | Extraer texto y campos | merchant, date, amount | Automatiza captura |
| 4 | Document Understanding | Extraer tabla de l√≠neas | Items + precios | Detalle granular |
| 5 | Generative AI (resumen) | Generar resumen contable | Texto estructurado | Auditor√≠a r√°pida |
| 6 | DB 23ai Vector Search | Indexar descripci√≥n √≠tems | Embeddings + √≠ndice | B√∫squedas sem√°nticas futuras |
| 7 | Dashboard / Reporting | Visualizar m√©tricas | KPIs gastos | Decisi√≥n financiera |

### ‚öôÔ∏è M√©tricas Relevantes por Tipo
| Tipo Modelo | M√©trica Clave | Complementarias | Riesgo t√≠pico |
|-------------|--------------|-----------------|--------------|
| Clasificaci√≥n (Vision/Language) | Accuracy / F1 | Precision, Recall | Desbalance clases |
| Detecci√≥n Objetos | mAP (IoU thresholds) | Recall por clase | Occlusi√≥n / escala |
| OCR / Extracci√≥n Campos | Exactitud campo | Confianza agregada | Texto borroso |
| Speech | Word Error Rate (WER) | Char Error Rate, Latencia | Ruido ambiente |
| Generative | Coherencia sem√°ntica | Perplexity, BLEU/ROUGE | Alucinaci√≥n |
| Vector Search | Similaridad (coseno) | Latencia consulta | Embeddings inconsistentes |

> Nota: Las m√©tricas exactas de la plataforma pueden presentarse como puntuaciones de confianza; el examen tiende a evaluar comprensi√≥n conceptual (qu√© m√©trica se aplica y por qu√©) m√°s que f√≥rmulas avanzadas.

### ÔøΩüìÇ Servicios Principales
| Servicio | Funci√≥n | Ejemplos Funcionales | Preguntas Relacionadas |
|----------|--------|----------------------|------------------------|
| Vision üñºÔ∏è | Imagen/Documento | OCR, key-value, detecci√≥n | Q9, Q14, Q32, Q33, Q38 |
| Language üó£Ô∏è | NLP | Sentimiento, clasificaci√≥n, NER | Q35 |
| Speech üéôÔ∏è | Voz a texto | Transcripci√≥n, SRT, confianza | Q12, Q13, Q17, Q19 |
| Document Understanding üìÑ | Extraer estructura | Tipo doc, tablas, pares | Complementario |
| Data Science üß™ | Ciclo ML | Notebook, cat√°logo, despliegue | Q5, varios |
| Generative AI ‚ú® | LLM y PEFT | Prompting, T-Few | Q10, Q15, Q22‚ÄìQ30 |
| Vector Search üîç | Sem√°ntica | Embeddings + ONNX | Q22, Q23, Q37 |

---

---
## üìä Distribuci√≥n Te√≥rica (Estimada)

1. **AI Fundamentals (‚âà10%)**
	- Diferencias entre AI (paraguas), ML (aprende de datos), DL (redes profundas).
	- Tipos de datos: estructurados, no estructurados (texto, imagen, audio), semiestructurados.
	- Ejemplos: asistentes virtuales, reconocimiento de voz, visi√≥n artificial, recomendadores.
	- Ciclo de vida alto nivel: problema -> datos -> modelo -> despliegue -> monitoreo -> mejora.

2. **Machine Learning Fundamentals (‚âà15%)**
	- Componentes: dataset, features (X), labels (y), split (train/validation/test).
	- Supervisado: regresi√≥n (valor continuo), clasificaci√≥n (etiquetas discretas).
	- No supervisado: clustering (descubrir grupos), reducci√≥n dimensionalidad (PCA, t-SNE) para visualizar/mitigar ruido.
	- Overfitting vs Underfitting:
		 - Overfitting: baja p√©rdida train, alta p√©rdida test.
		 - Underfitting: alta p√©rdida tanto train como test (modelo demasiado simple).
	- T√©cnicas de mitigaci√≥n: regularizaci√≥n (L2, dropout), m√°s datos, early stopping, data augmentation.
	- M√©tricas:
		 - Accuracy = (TP+TN)/(Total)
		 - Precision = TP/(TP+FP) (Qu√© tan confiables son los positivos predichos)
		 - Recall = TP/(TP+FN) (Qu√© porcentaje de positivos reales recuperamos)
		 - F1 = 2 * (precision * recall) / (precision + recall)
		 - AUC-ROC para discriminaci√≥n binaria, MAE/MSE para regresi√≥n.
	- Evaluaci√≥n adecuada: evitar leakage, k-fold cross validation cuando datos escasos.

3. **Deep Learning Fundamentals (‚âà10%)**
	- Redes neuronales profundas: capas lineales + activaciones no lineales (ReLU, GELU).
	- CNN: convoluciones, filtros, pooling, extracci√≥n jer√°rquica (bordes -> texturas -> objetos).
	- RNN/LSTM/GRU: manejo secuencial, problemas de vanishing/exploding gradient.
	- Transformers: atenci√≥n multi-cabeza, paralelizaci√≥n, mejores para dependencias largas.
	- Par√°metros vs hiperpar√°metros (learning rate, batch size, n√∫mero de capas).
	- Regularizaci√≥n DL: dropout, batch normalization, weight decay.

4. **Generative AI & Large Language Models (‚âà15%)**
	- Modelos generativos: aprenden distribuci√≥n de datos (auto-regresivos, diffusion, VAEs, GANs).
	- LLMs (Transformers): embeddings -> bloques atenci√≥n -> capa salida (softmax tokens).
	- In-Context Learning: ejemplos en el prompt; sin cambio de pesos.
	- Fine-tuning vs Parameter-efficient (LoRA, adapters, T-Few) para reducir costo.
	- Prompt Engineering: claridad, rol, ejemplos, restricciones (format specs), chain-of-thought opcional.
	- Evaluaci√≥n generativa:
		 - Perplexity (fluidez), BLEU/ROUGE (similaridad n-gramas), METEOR (alineaci√≥n sem√°ntica), Human eval (calidad subjetiva), Toxicity checks.
	- Riesgos: alucinaciones, sesgos, fuga de informaci√≥n (prompt injection), coste de c√≥mputo.

5. **OCI AI Services & Infrastructure (‚âà10%)**
	- AI Services:
		 - Vision: OCR, clasificaci√≥n documento, extracci√≥n clave-valor, detecci√≥n objetos.
		 - Language: clasificaci√≥n, sentimiento, NER, detecci√≥n idioma.
		 - Speech: transcripci√≥n, normalizaci√≥n, puntuaci√≥n confianza, archivos SRT, filtrado lenguaje (tagging/masking/removing).
		 - Document Understanding: OCR + estructuraci√≥n avanzada (no transcribe audio).
		 - Anomaly Detection: series temporales; modelado patrones y desviaciones.
		 - Generative AI: acceso a LLMs, T-Few, embeddings.
	- Data Science:
		 - Notebook Sessions (entorno interactivo), Model Catalog (registro/versionado), Deployment (endpoints), ADS SDK.
	- Infraestructura:
		 - Superclusters: GPUs de alta densidad + RDMA (latencia baja). Escala para LLM y entrenamiento intensivo.
		 - GPUs: A100 (escala mediana), GB200 (exascala y entrenamiento extremo), roles comparativos.
		 - Almacenamiento y red: Object Storage para datasets, Block para rendimiento, RDMA para throughput inter-nodos.
	- AI Vector Search:
		 - Embeddings para b√∫squeda sem√°ntica (texto, documentos, potencial multimodal).
		 - √çndices vectoriales: aproximaci√≥n vs exacta (ANN ‚Äì HNSW, IVF; conceptual).
		 - ONNX dentro de Database 23ai para inferencia cercana a los datos.
	- Gobernanza y seguridad:
		 - Uso de OCI Vault para llaves y secretos (no parte directa del c√≥mputo AI).
		 - Principios de Trustworthy AI (lawful, ethical, robust) aplicados a despliegues.

6. **Evaluaci√≥n y Monitoreo (Complementario)**
	- Monitoreo post-despliegue: drift de datos, degradaci√≥n de m√©tricas, latencia.
	- Observabilidad: logging inferencias, tasas de error, perfilado de GPU.
	- Re-entrenamiento programado vs bajo demanda (trigger por ca√≠da m√©trica).

7. **Optimizaci√≥n y Coste**
	- Escalado horizontal vs vertical (m√°s nodos vs GPU m√°s potente).
	- T√©cnicas de ahorro: PEFT (T-Few), batching, caching embeddings.
	- Elecci√≥n de forma de c√≥mputo: ajustar recursos a etapa (experimento vs producci√≥n).

8. **Buenas Pr√°cticas de Prompting (Generative)**
	- Estructura sugerida: (Rol) + (Instrucci√≥n clara) + (Ejemplos opcionales) + (Formato esperado) + (Restricciones).
	- Evitar ambig√ºedad y peticiones m√∫ltiples sin delimitadores.
	- Uso de delimitadores (```texto```) para evitar inyecci√≥n accidental.

9. **Riesgos y Mitigaci√≥n**
	- Sesgo: diversificar dataset, auditor√≠as.
	- Seguridad: sanitizar entrada, limitar capacidad de ejecutar c√≥digo, rotar llaves.
	- Privacidad: anonimizaci√≥n de datos sensibles, encriptaci√≥n en reposo y tr√°nsito.

10. **Resumen F√≥rmulas Clave**
	- Accuracy = (TP+TN)/(TP+TN+FP+FN)
	- Precision = TP/(TP+FP)
	- Recall = TP/(TP+FN)
	- F1 = 2*(Precision*Recall)/(Precision+Recall)
	- MSE = (1/n) Œ£ (y_pred - y_true)^2
	- Perplexity ‚âà exp(average cross-entropy)

---

## üéØ Objetivo
Explicar el contenido base que origin√≥ el banco de preguntas y proporcionar una gu√≠a conceptual extendida para reforzar y mejorar la calidad de futuras preguntas del examen OCI Foundations con √©nfasis en servicios de IA y conceptos de Machine Learning.

## üåê Panorama General de OCI
Oracle Cloud Infrastructure (OCI) ofrece servicios para c√≥mputo, almacenamiento, networking y plataformas especializadas (Data Science, AI Services, Database 23ai). El examen Foundations cubre:
- Principios de la nube (IaaS, PaaS, SaaS)
- Arquitectura de OCI (regiones, dominios de disponibilidad, dominios de fallas)
- Identidad y seguridad (IAM, pol√≠ticas, compartimentos, cifrado)
- Servicios base: Compute, Object Storage, Block Storage, VCN, Load Balancer, Autonomous Database
- Facturaci√≥n y soporte (modelos de precio, SLA, niveles de soporte)

## üõ†Ô∏è Servicios de IA en OCI
### üß™ OCI Data Science
Entorno administrado para:
- Notebook Sessions: Desarrollo interactivo (Python, ADS SDK).
- Model Training: Entrenamiento de modelos tradicionales y deep learning.
- Model Catalog: Versionar, registrar, gobernar modelos.
- Model Deployment: Exponer endpoints de inferencia gestionados.
- Integration: Conda packs, GPUs (en formas disponibles), logging y monitoreo.

### üß© OCI AI Services
Servicios pre-entrenados listos para integraci√≥n mediante API/SDK:
- Vision: Clasificaci√≥n de im√°genes y documentos, OCR, extracci√≥n clave-valor, detecci√≥n de objetos.
- Language: Clasificaci√≥n de texto (gran conjunto de categor√≠as), sentimiento, detecci√≥n de idioma, NER.
- Speech: Transcripci√≥n de audio, normalizaci√≥n, puntuaci√≥n de confianza, soporte SRT, filtrado de lenguaje (tagging/masking/removing).
- Anomaly Detection (no detallado en preguntas oficiales): Identificaci√≥n de patrones an√≥malos en series temporales.
- Generative AI: Modelos LLM para prompting, few-shot y fine-tuning eficiente (T-Few).

### üóÑÔ∏è Oracle Database 23ai y Vector Search
- Integraci√≥n de embeddings directamente en la base de datos.
- Carga de modelos ONNX para generar representaciones vectoriales.
- Consultas sem√°nticas mezclando SQL y b√∫squeda vectorial.
- Reducci√≥n de latencia al evitar extracci√≥n masiva de datos.

## üß† Conceptos Clave de ML/DL
| Concepto | Definici√≥n | Relaci√≥n Preguntas | Emoji |
|----------|------------|--------------------|-------|
| Overfitting | Memoriza entrenamiento, falla en test | Q4 | üîÅ |
| Inference | Uso del modelo para nuevos datos | Q21 | üì§ |
| Regression | Predicci√≥n continua | Q6 | üìà |
| Classification | Predicci√≥n de etiquetas discretas | Q35, Q39 | üè∑Ô∏è |
| RNN | Manejo de secuencias temporales | Q18, Q29, Q36 | üîÑ |
| CNN | Patrones espaciales en im√°genes | Q33, Q38 | üñºÔ∏è |
| Tokens | Unidades m√≠nimas de texto | Q28 | ‚úÇÔ∏è |
| Few-Shot | Ejemplos cortos en prompt | Q27 | üéØ |
| In-Context Learning | Adaptaci√≥n sin cambiar pesos | Opcional O106 | üß© |
| T-Few (PEFT) | Fine-tuning eficiente parcial | Q10 | ‚öôÔ∏è |
| Vanishing Gradient | Gradiente se aten√∫a en secuencias largas | Q36 | ü•Ä |
| Loss Function | Mide error para optimizar | Q41 | üìâ |

## üõ°Ô∏è Trustworthy AI
Principios: Lawful, Ethical, Robust.
- Lawful: Cumplimiento regulatorio (privacidad, protecci√≥n de datos).
- Ethical: Minimizar sesgos, transparencia, uso responsable.
- Robust: Fiabilidad t√©cnica y resistencia a ataques adversarios.
Aplicaci√≥n pr√°ctica: Monitoreo post-despliegue, auditor√≠as de modelos, filtrado de contenido.

## ‚öôÔ∏è Infraestructura para AI en OCI
### üèóÔ∏è Superclusters
- Conjuntos de nodos GPU de alta densidad.
- Red RDMA para baja latencia y alto ancho de banda.
- Escalabilidad para entrenamiento de LLM y modelos de visi√≥n a gran escala.

### üß≤ GPUs Disponibles
- A100: Escala peque√±a-mediana (equilibrio rendimiento/memoria).
- GB200: Escenarios masivos (Grace Blackwell, exascala, HPC extremo).
- H100/H200: Generaciones avanzadas (no directamente preguntadas, pero relevantes en comparaci√≥n).

### üö´ Componentes NO de AI Compute
- OCI Vault: Gesti√≥n de llaves y secretos (seguridad), no c√≥mputo de IA.

## üß™ Dise√±o de Preguntas y Mejora Continua
Para mejorar la calidad de las preguntas:
1. Evitar duplicados sem√°nticos salvo que refuercen (ej: Select AI repetido -> fusionar en una pregunta multi-parte).
2. Incluir distractores plausibles (opciones incorrectas que representen errores comunes reales).
3. A√±adir contexto breve (escenario de negocio) para aumentar aplicabilidad.
4. Balancear taxonom√≠a cognitiva (recordar, comprender, aplicar, analizar).
5. Revisar conclusiones contra documentaci√≥n oficial para evitar ambig√ºedades.

### üîß Ejemplo de Mejora
Pregunta original: "GPU para massive-scale?" -> A√±adir contexto: "Entrenar un LLM multiling√ºe de cientos de miles de millones de par√°metros" para reforzar la elecci√≥n de GB200.

### ‚ö†Ô∏è Errores Comunes a Vigilar
- Confundir OCR con Document Classification.
- Usar 'in-context learning' como sin√≥nimo de fine-tuning (son distintos).
- Considerar que Vector Search hace coincidencia exacta de palabras (usa similitud sem√°ntica).
- Asumir que cualquier capa oculta 'produce la salida final'.

## üìö Estrategias de Estudio Sugeridas
- Bloques tematizados (Vision, Speech, Language, Infra, Prompting).
- Pr√°cticas espaciadas: repetir cada bloque 24h despu√©s.
- T√©cnica de Ense√±ar: Explicar cada concepto a otra persona o grabar un audio explicativo.
- Registro de Fallos: Usar `last_wrong.json` (quiz) para enfocarse en debilidades.

## üó∫Ô∏è Mapa de Preguntas por Tema
| Tema | Preguntas Oficiales | Opcionales | Icono |
|------|---------------------|-----------|-------|
| Vision | Q9, Q14, Q32, Q33, Q38 | O103 | üñºÔ∏è |
| Speech | Q12, Q13, Q17, Q19 | O107 | üéôÔ∏è |
| Language | Q35 | O101, O109 | üó£Ô∏è |
| Generative / LLM | Q10, Q15, Q22, Q23, Q27‚ÄìQ30, Q41 | O104, O106 | ‚ú® |
| Infra / GPUs | Q24‚ÄìQ26 | O105 | üß≤ |
| Core ML | Q3, Q4, Q6, Q21, Q31, Q34, Q36, Q39, Q40 | O102 | üîß |
| Database / Vector | Q22, Q23, Q37 | O108 | üîç |
| Trustworthy AI | Q20 | - | üõ°Ô∏è |

## üîÆ Pr√≥ximas Extensiones
- A√±adir secci√≥n de preguntas de desarrollo seguro y compliance.
- Incorporar ejemplos de prompts optimizados (zero-shot vs few-shot vs chain-of-thought).
- A√±adir m√©tricas de evaluaci√≥n: precisi√≥n, recall, F1 (no incluidas a√∫n).
- Explorar casos de uso multi-servicio (Vision + Language + DB 23ai).

## üìé Referencias Sugeridas
(No se incluyen URLs directas para evitar dependencia; buscar en documentaci√≥n oficial OCI):
- OCI Data Science Documentation
- OCI AI Services Overview
- Oracle Database 23ai Vector Search Guide
- Trustworthy AI Principles (Oracle / Industria)

## üßæ Glosario R√°pido
| T√©rmino | Definici√≥n Breve | Emoji |
|---------|------------------|-------|
| Embedding | Vector sem√°ntico denso de texto/imagen | üîó |
| Token | Unidad m√≠nima de entrada LLM | ‚úÇÔ∏è |
| Endpoint de Inferencia | API que expone predicciones | üöÄ |
| OCR | Extracci√≥n de texto en im√°genes | üîç |
| Key-Value Extraction | Pares estructurados (doc) | üßæ |
| Few-Shot | Pocos ejemplos en prompt | üéØ |
| In-Context Learning | Adaptaci√≥n sin reentrenar | üß© |
| Vanishing Gradient | Gradiente que se extingue | ü•Ä |
| T-Few | Fine-tuning eficiente | ‚öôÔ∏è |
| RDMA | Red de baja latencia | üöÑ |
| Loss Function | Mide error optimizaci√≥n | üìâ |

## ‚úÖ Checklist de Calidad para Nuevas Preguntas
Antes de agregar una nueva pregunta:
1. ¬øEl distractor m√°s plausible refleja un error conceptual com√∫n?
2. ¬øLa respuesta es inequ√≠voca con base en documentaci√≥n oficial?
3. ¬øEl escenario aporta aplicaci√≥n pr√°ctica (si corresponde)?
4. ¬øEvita ambig√ºedad terminol√≥gica (OCR vs Clasificaci√≥n Documentos)?
5. ¬øNo duplica innecesariamente otra pregunta sin variar el √°ngulo cognitivo?

## üèÅ Conclusi√≥n
Este documento extiende el material inicial proporcionando una base te√≥rica estructurada y criterios de mejora continua para el banco de preguntas. √ösalo junto con el `quiz.py` para un ciclo de aprendizaje activo: leer -> probar -> analizar fallos -> reforzar.

---
Fin de documentaci√≥n.

---
## üì¶ Nuevas Preguntas Propuestas (Generadas Originalmente)
Estas NO provienen de fuentes externas copiadas; se dise√±an para ampliar cobertura conceptual.

1. Vision Key-Value Extraction ‚Äì ¬øCu√°l es la principal ventaja frente a solo OCR?
	A. Reduce tama√±o de archivo
	B. Elimina necesidad de indexar
	C. Proporciona estructura sem√°ntica con campos espec√≠ficos ‚úÖ
	D. Convierte im√°genes en audio
	Explicaci√≥n: OCR da texto plano; key-value a√±ade pares sem√°nticos listos para bases de datos.

2. Document Understanding vs Vision ‚Äì ¬øCu√°ndo preferir Document Understanding para tablas?
	A. Cuando se requieren bounding boxes de objetos peque√±os
	B. Cuando la prioridad es texto continuo sin estructura
	C. Cuando se necesita reconstruir celdas y encabezados coherentes ‚úÖ
	D. Cuando se traducen idiomas en l√≠nea
	Explicaci√≥n: Document Understanding encapsula estructura tabular mejor que OCR puro.

3. Speech Normalization ‚Äì ¬øQu√© transforma 12/10/2025 y ‚Äúwww.example.com‚Äù en formato est√°ndar?
	A. Confidence scoring
	B. Profanity tagging
	C. Normalization ‚úÖ
	D. SRT alignment
	Explicaci√≥n: Normalization estandariza n√∫meros, fechas, URLs para lectura uniforme.

4. Vector Search ‚Äì ¬øQu√© sucede si dos documentos comparten sin√≥nimos pero pocas palabras exactas?
	A. No se pueden encontrar
	B. B√∫squeda sem√°ntica a√∫n los asocia por embeddings ‚úÖ
	C. Requiere stemming manual
	D. Solo coincide si hay mismo n√∫mero de tokens
	Explicaci√≥n: Embeddings capturan significado m√°s all√° de coincidencia literal.

5. Generative AI Seguridad ‚Äì ¬øCu√°l es una mitigaci√≥n ante prompt injection?
	A. Aumentar batch size
	B. Sanitizar y delimitar contenido del usuario ‚úÖ
	C. Usar m√°s GPUs
	D. Reducir tokens
	Explicaci√≥n: Delimitadores y limpieza previenen ejecuci√≥n de instrucciones maliciosas.

6. Vision Object Detection ‚Äì M√©trica adecuada para evaluar superposici√≥n entre predicci√≥n y verdad:
	A. Perplexity
	B. Intersection over Union (IoU) ‚úÖ
	C. Word Error Rate
	D. Cosine similarity pura
	Explicaci√≥n: IoU mide calidad de bounding box; se agrega en mAP.

7. Speech ‚Äì ¬øPor qu√© incluir SRT export en pipeline de transcripci√≥n?
	A. Reduce consumo GPU
	B. Facilita subtitulado sincronizado en video ‚úÖ
	C. Mejora privacidad
	D. Deshabilita tagging
	Explicaci√≥n: SRT est√°ndar facilita integraci√≥n multimedia.

8. Trustworthy AI ‚Äì ¬øEjemplo pr√°ctico de Robust?
	A. Modelo ignora auditor√≠as
	B. Sistema incluye pruebas adversariales para inputs manipulados ‚úÖ
	C. Elimina logs
	D. Expone contrase√±as para depurar
	Explicaci√≥n: Robustez implica resistencia frente a ataques o ruido.

9. GPUs ‚Äì ¬øPor qu√© elegir A100 en fase experimental en vez de GB200?
	A. Mayor exascala necesaria
	B. Coste y escala ajustados a pruebas medianas ‚úÖ
	C. A100 no soporta entrenamiento
	D. GB200 menor latencia siempre
	Explicaci√≥n: A100 balance costo/rendimiento para iteraci√≥n antes de escalar.

10. Embeddings ‚Äì ¬øQu√© pasa si se mezclan embeddings generados con distintos modelos en mismo √≠ndice Vector Search?
	 A. Mejora precisi√≥n
	 B. Degrada coherencia sem√°ntica y similitud ‚úÖ
	 C. Acelera consultas
	 D. Obliga a usar labeled data
	 Explicaci√≥n: Embeddings inconsistentes producen distancias no comparables.

> Puedes integrar estas propuestas al banco opcional marc√°ndolas con nuevos IDs (O110+), manteniendo trazabilidad.

---
## ‚öñÔ∏è Nota sobre Fuentes Externas
Se han referenciado p√∫blicamente enlaces (Scribd, repositorio GitHub) pero NO se copia texto directo para evitar infringir derechos. El contenido aqu√≠ es s√≠ntesis original basada en conocimiento general de OCI y pr√°cticas comunes de examen de fundamentos.

