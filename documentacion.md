# üìò Documentaci√≥n Ampliada OCI Foundations (AI Focus)

> Gu√≠a enriquecida para el examen **Oracle Cloud Infrastructure AI Foundations Associate (1Z0-1122-25)**.
> Incluye conceptos clave, servicios, m√©tricas, buenas pr√°cticas y mapa tem√°tico de preguntas oficiales.

## üîç Tabla de Contenidos
1. [Resumen Ejecutivo](#-resumen-ejecutivo)
2. [Distribuci√≥n Te√≥rica](#-distribuci√≥n-te√≥rica)
3. [Panorama General OCI](#-panorama-general-de-oci)
4. [Servicios de IA en OCI](#-servicios-de-ia-en-oci)
5. [Conceptos Clave ML/DL](#-conceptos-clave-de-mldl)
6. [Trustworthy AI](#-trustworthy-ai)
7. [Infraestructura para AI](#-infraestructura-para-ai-en-oci)
8. [Dise√±o de Preguntas](#-dise√±o-de-preguntas-y-mejora-continua)
9. [Estrategias de Estudio](#-estrategias-de-estudio-sugeridas)
10. [Mapa de Preguntas](#-mapa-de-preguntas-por-tema)
11. [Extensiones Futuras](#-pr√≥ximas-extensiones)
12. [Referencias Sugeridas](#-referencias-sugeridas)
13. [Glosario](#-glosario-r√°pido)
14. [Checklist Calidad](#-checklist-de-calidad-para-nuevas-preguntas)
15. [Conclusi√≥n](#-conclusi√≥n)

---
## üöÄ Resumen Ejecutivo

| √Årea | Idea Clave | Ejemplo | Por qu√© Importa |
|------|------------|---------|-----------------|
| IA | Simula procesos cognitivos | Asistente virtual | Cubre dominio general del examen |
| ML | Aprende patrones de datos | Clasificador de spam | N√∫cleo de varias preguntas |
| DL | Redes profundas especializadas | CNN en visi√≥n | Potencia tareas complejas |
| Generative AI | Crea nuevo contenido | LLM redactando texto | Nuevo foco en fundamentos |
| Servicios OCI AI | APIs pre-entrenadas | Vision / Language / Speech | Facilitan integraci√≥n r√°pida |

### üìÇ Servicios Principales
| Servicio | Funci√≥n | Ejemplos Funcionales | Preguntas Relacionadas |
|----------|--------|----------------------|------------------------|
| Vision üñºÔ∏è | Imagen/Documento | OCR, key-value, detecci√≥n | Q9, Q14, Q32, Q33, Q38 |
| Language üó£Ô∏è | NLP | Sentimiento, clasificaci√≥n, NER | Q35 |
| Speech üéôÔ∏è | Voz a texto | Transcripci√≥n, SRT, confianza | Q12, Q13, Q17, Q19 |
| Document Understanding üìÑ | Extraer estructura | Tipo doc, tablas, pares | Complementario |
| Data Science üß™ | Ciclo ML | Notebook, cat√°logo, despliegue | Q5, varios |
| Generative AI ‚ú® | LLM y PEFT | Prompting, T-Few | Q10, Q15, Q22‚ÄìQ30 |
| Vector Search üîç | Sem√°ntica | Embeddings + ONNX | Q22, Q23, Q37 |

---

---
## üìä Distribuci√≥n Te√≥rica (Estimada)

1. **AI Fundamentals (‚âà10%)**
	- Diferencias entre AI (paraguas), ML (aprende de datos), DL (redes profundas).
	- Tipos de datos: estructurados, no estructurados (texto, imagen, audio), semiestructurados.
	- Ejemplos: asistentes virtuales, reconocimiento de voz, visi√≥n artificial, recomendadores.
	- Ciclo de vida alto nivel: problema -> datos -> modelo -> despliegue -> monitoreo -> mejora.

2. **Machine Learning Fundamentals (‚âà15%)**
	- Componentes: dataset, features (X), labels (y), split (train/validation/test).
	- Supervisado: regresi√≥n (valor continuo), clasificaci√≥n (etiquetas discretas).
	- No supervisado: clustering (descubrir grupos), reducci√≥n dimensionalidad (PCA, t-SNE) para visualizar/mitigar ruido.
	- Overfitting vs Underfitting:
		 - Overfitting: baja p√©rdida train, alta p√©rdida test.
		 - Underfitting: alta p√©rdida tanto train como test (modelo demasiado simple).
	- T√©cnicas de mitigaci√≥n: regularizaci√≥n (L2, dropout), m√°s datos, early stopping, data augmentation.
	- M√©tricas:
		 - Accuracy = (TP+TN)/(Total)
		 - Precision = TP/(TP+FP) (Qu√© tan confiables son los positivos predichos)
		 - Recall = TP/(TP+FN) (Qu√© porcentaje de positivos reales recuperamos)
		 - F1 = 2 * (precision * recall) / (precision + recall)
		 - AUC-ROC para discriminaci√≥n binaria, MAE/MSE para regresi√≥n.
	- Evaluaci√≥n adecuada: evitar leakage, k-fold cross validation cuando datos escasos.

3. **Deep Learning Fundamentals (‚âà10%)**
	- Redes neuronales profundas: capas lineales + activaciones no lineales (ReLU, GELU).
	- CNN: convoluciones, filtros, pooling, extracci√≥n jer√°rquica (bordes -> texturas -> objetos).
	- RNN/LSTM/GRU: manejo secuencial, problemas de vanishing/exploding gradient.
	- Transformers: atenci√≥n multi-cabeza, paralelizaci√≥n, mejores para dependencias largas.
	- Par√°metros vs hiperpar√°metros (learning rate, batch size, n√∫mero de capas).
	- Regularizaci√≥n DL: dropout, batch normalization, weight decay.

4. **Generative AI & Large Language Models (‚âà15%)**
	- Modelos generativos: aprenden distribuci√≥n de datos (auto-regresivos, diffusion, VAEs, GANs).
	- LLMs (Transformers): embeddings -> bloques atenci√≥n -> capa salida (softmax tokens).
	- In-Context Learning: ejemplos en el prompt; sin cambio de pesos.
	- Fine-tuning vs Parameter-efficient (LoRA, adapters, T-Few) para reducir costo.
	- Prompt Engineering: claridad, rol, ejemplos, restricciones (format specs), chain-of-thought opcional.
	- Evaluaci√≥n generativa:
		 - Perplexity (fluidez), BLEU/ROUGE (similaridad n-gramas), METEOR (alineaci√≥n sem√°ntica), Human eval (calidad subjetiva), Toxicity checks.
	- Riesgos: alucinaciones, sesgos, fuga de informaci√≥n (prompt injection), coste de c√≥mputo.

5. **OCI AI Services & Infrastructure (‚âà10%)**
	- AI Services:
		 - Vision: OCR, clasificaci√≥n documento, extracci√≥n clave-valor, detecci√≥n objetos.
		 - Language: clasificaci√≥n, sentimiento, NER, detecci√≥n idioma.
		 - Speech: transcripci√≥n, normalizaci√≥n, puntuaci√≥n confianza, archivos SRT, filtrado lenguaje (tagging/masking/removing).
		 - Document Understanding: OCR + estructuraci√≥n avanzada (no transcribe audio).
		 - Anomaly Detection: series temporales; modelado patrones y desviaciones.
		 - Generative AI: acceso a LLMs, T-Few, embeddings.
	- Data Science:
		 - Notebook Sessions (entorno interactivo), Model Catalog (registro/versionado), Deployment (endpoints), ADS SDK.
	- Infraestructura:
		 - Superclusters: GPUs de alta densidad + RDMA (latencia baja). Escala para LLM y entrenamiento intensivo.
		 - GPUs: A100 (escala mediana), GB200 (exascala y entrenamiento extremo), roles comparativos.
		 - Almacenamiento y red: Object Storage para datasets, Block para rendimiento, RDMA para throughput inter-nodos.
	- AI Vector Search:
		 - Embeddings para b√∫squeda sem√°ntica (texto, documentos, potencial multimodal).
		 - √çndices vectoriales: aproximaci√≥n vs exacta (ANN ‚Äì HNSW, IVF; conceptual).
		 - ONNX dentro de Database 23ai para inferencia cercana a los datos.
	- Gobernanza y seguridad:
		 - Uso de OCI Vault para llaves y secretos (no parte directa del c√≥mputo AI).
		 - Principios de Trustworthy AI (lawful, ethical, robust) aplicados a despliegues.

6. **Evaluaci√≥n y Monitoreo (Complementario)**
	- Monitoreo post-despliegue: drift de datos, degradaci√≥n de m√©tricas, latencia.
	- Observabilidad: logging inferencias, tasas de error, perfilado de GPU.
	- Re-entrenamiento programado vs bajo demanda (trigger por ca√≠da m√©trica).

7. **Optimizaci√≥n y Coste**
	- Escalado horizontal vs vertical (m√°s nodos vs GPU m√°s potente).
	- T√©cnicas de ahorro: PEFT (T-Few), batching, caching embeddings.
	- Elecci√≥n de forma de c√≥mputo: ajustar recursos a etapa (experimento vs producci√≥n).

8. **Buenas Pr√°cticas de Prompting (Generative)**
	- Estructura sugerida: (Rol) + (Instrucci√≥n clara) + (Ejemplos opcionales) + (Formato esperado) + (Restricciones).
	- Evitar ambig√ºedad y peticiones m√∫ltiples sin delimitadores.
	- Uso de delimitadores (```texto```) para evitar inyecci√≥n accidental.

9. **Riesgos y Mitigaci√≥n**
	- Sesgo: diversificar dataset, auditor√≠as.
	- Seguridad: sanitizar entrada, limitar capacidad de ejecutar c√≥digo, rotar llaves.
	- Privacidad: anonimizaci√≥n de datos sensibles, encriptaci√≥n en reposo y tr√°nsito.

10. **Resumen F√≥rmulas Clave**
	- Accuracy = (TP+TN)/(TP+TN+FP+FN)
	- Precision = TP/(TP+FP)
	- Recall = TP/(TP+FN)
	- F1 = 2*(Precision*Recall)/(Precision+Recall)
	- MSE = (1/n) Œ£ (y_pred - y_true)^2
	- Perplexity ‚âà exp(average cross-entropy)

---

## üéØ Objetivo
Explicar el contenido base que origin√≥ el banco de preguntas y proporcionar una gu√≠a conceptual extendida para reforzar y mejorar la calidad de futuras preguntas del examen OCI Foundations con √©nfasis en servicios de IA y conceptos de Machine Learning.

## üåê Panorama General de OCI
Oracle Cloud Infrastructure (OCI) ofrece servicios para c√≥mputo, almacenamiento, networking y plataformas especializadas (Data Science, AI Services, Database 23ai). El examen Foundations cubre:
- Principios de la nube (IaaS, PaaS, SaaS)
- Arquitectura de OCI (regiones, dominios de disponibilidad, dominios de fallas)
- Identidad y seguridad (IAM, pol√≠ticas, compartimentos, cifrado)
- Servicios base: Compute, Object Storage, Block Storage, VCN, Load Balancer, Autonomous Database
- Facturaci√≥n y soporte (modelos de precio, SLA, niveles de soporte)

## üõ†Ô∏è Servicios de IA en OCI
### üß™ OCI Data Science
Entorno administrado para:
- Notebook Sessions: Desarrollo interactivo (Python, ADS SDK).
- Model Training: Entrenamiento de modelos tradicionales y deep learning.
- Model Catalog: Versionar, registrar, gobernar modelos.
- Model Deployment: Exponer endpoints de inferencia gestionados.
- Integration: Conda packs, GPUs (en formas disponibles), logging y monitoreo.

### üß© OCI AI Services
Servicios pre-entrenados listos para integraci√≥n mediante API/SDK:
- Vision: Clasificaci√≥n de im√°genes y documentos, OCR, extracci√≥n clave-valor, detecci√≥n de objetos.
- Language: Clasificaci√≥n de texto (gran conjunto de categor√≠as), sentimiento, detecci√≥n de idioma, NER.
- Speech: Transcripci√≥n de audio, normalizaci√≥n, puntuaci√≥n de confianza, soporte SRT, filtrado de lenguaje (tagging/masking/removing).
- Anomaly Detection (no detallado en preguntas oficiales): Identificaci√≥n de patrones an√≥malos en series temporales.
- Generative AI: Modelos LLM para prompting, few-shot y fine-tuning eficiente (T-Few).

### üóÑÔ∏è Oracle Database 23ai y Vector Search
- Integraci√≥n de embeddings directamente en la base de datos.
- Carga de modelos ONNX para generar representaciones vectoriales.
- Consultas sem√°nticas mezclando SQL y b√∫squeda vectorial.
- Reducci√≥n de latencia al evitar extracci√≥n masiva de datos.

## üß† Conceptos Clave de ML/DL
| Concepto | Definici√≥n | Relaci√≥n Preguntas | Emoji |
|----------|------------|--------------------|-------|
| Overfitting | Memoriza entrenamiento, falla en test | Q4 | üîÅ |
| Inference | Uso del modelo para nuevos datos | Q21 | üì§ |
| Regression | Predicci√≥n continua | Q6 | üìà |
| Classification | Predicci√≥n de etiquetas discretas | Q35, Q39 | üè∑Ô∏è |
| RNN | Manejo de secuencias temporales | Q18, Q29, Q36 | üîÑ |
| CNN | Patrones espaciales en im√°genes | Q33, Q38 | üñºÔ∏è |
| Tokens | Unidades m√≠nimas de texto | Q28 | ‚úÇÔ∏è |
| Few-Shot | Ejemplos cortos en prompt | Q27 | üéØ |
| In-Context Learning | Adaptaci√≥n sin cambiar pesos | Opcional O106 | üß© |
| T-Few (PEFT) | Fine-tuning eficiente parcial | Q10 | ‚öôÔ∏è |
| Vanishing Gradient | Gradiente se aten√∫a en secuencias largas | Q36 | ü•Ä |
| Loss Function | Mide error para optimizar | Q41 | üìâ |

## üõ°Ô∏è Trustworthy AI
Principios: Lawful, Ethical, Robust.
- Lawful: Cumplimiento regulatorio (privacidad, protecci√≥n de datos).
- Ethical: Minimizar sesgos, transparencia, uso responsable.
- Robust: Fiabilidad t√©cnica y resistencia a ataques adversarios.
Aplicaci√≥n pr√°ctica: Monitoreo post-despliegue, auditor√≠as de modelos, filtrado de contenido.

## ‚öôÔ∏è Infraestructura para AI en OCI
### üèóÔ∏è Superclusters
- Conjuntos de nodos GPU de alta densidad.
- Red RDMA para baja latencia y alto ancho de banda.
- Escalabilidad para entrenamiento de LLM y modelos de visi√≥n a gran escala.

### üß≤ GPUs Disponibles
- A100: Escala peque√±a-mediana (equilibrio rendimiento/memoria).
- GB200: Escenarios masivos (Grace Blackwell, exascala, HPC extremo).
- H100/H200: Generaciones avanzadas (no directamente preguntadas, pero relevantes en comparaci√≥n).

### üö´ Componentes NO de AI Compute
- OCI Vault: Gesti√≥n de llaves y secretos (seguridad), no c√≥mputo de IA.

## üß™ Dise√±o de Preguntas y Mejora Continua
Para mejorar la calidad de las preguntas:
1. Evitar duplicados sem√°nticos salvo que refuercen (ej: Select AI repetido -> fusionar en una pregunta multi-parte).
2. Incluir distractores plausibles (opciones incorrectas que representen errores comunes reales).
3. A√±adir contexto breve (escenario de negocio) para aumentar aplicabilidad.
4. Balancear taxonom√≠a cognitiva (recordar, comprender, aplicar, analizar).
5. Revisar conclusiones contra documentaci√≥n oficial para evitar ambig√ºedades.

### üîß Ejemplo de Mejora
Pregunta original: "GPU para massive-scale?" -> A√±adir contexto: "Entrenar un LLM multiling√ºe de cientos de miles de millones de par√°metros" para reforzar la elecci√≥n de GB200.

### ‚ö†Ô∏è Errores Comunes a Vigilar
- Confundir OCR con Document Classification.
- Usar 'in-context learning' como sin√≥nimo de fine-tuning (son distintos).
- Considerar que Vector Search hace coincidencia exacta de palabras (usa similitud sem√°ntica).
- Asumir que cualquier capa oculta 'produce la salida final'.

## üìö Estrategias de Estudio Sugeridas
- Bloques tematizados (Vision, Speech, Language, Infra, Prompting).
- Pr√°cticas espaciadas: repetir cada bloque 24h despu√©s.
- T√©cnica de Ense√±ar: Explicar cada concepto a otra persona o grabar un audio explicativo.
- Registro de Fallos: Usar `last_wrong.json` (quiz) para enfocarse en debilidades.

## üó∫Ô∏è Mapa de Preguntas por Tema
| Tema | Preguntas Oficiales | Opcionales | Icono |
|------|---------------------|-----------|-------|
| Vision | Q9, Q14, Q32, Q33, Q38 | O103 | üñºÔ∏è |
| Speech | Q12, Q13, Q17, Q19 | O107 | üéôÔ∏è |
| Language | Q35 | O101, O109 | üó£Ô∏è |
| Generative / LLM | Q10, Q15, Q22, Q23, Q27‚ÄìQ30, Q41 | O104, O106 | ‚ú® |
| Infra / GPUs | Q24‚ÄìQ26 | O105 | üß≤ |
| Core ML | Q3, Q4, Q6, Q21, Q31, Q34, Q36, Q39, Q40 | O102 | üîß |
| Database / Vector | Q22, Q23, Q37 | O108 | üîç |
| Trustworthy AI | Q20 | - | üõ°Ô∏è |

## üîÆ Pr√≥ximas Extensiones
- A√±adir secci√≥n de preguntas de desarrollo seguro y compliance.
- Incorporar ejemplos de prompts optimizados (zero-shot vs few-shot vs chain-of-thought).
- A√±adir m√©tricas de evaluaci√≥n: precisi√≥n, recall, F1 (no incluidas a√∫n).
- Explorar casos de uso multi-servicio (Vision + Language + DB 23ai).

## üìé Referencias Sugeridas
(No se incluyen URLs directas para evitar dependencia; buscar en documentaci√≥n oficial OCI):
- OCI Data Science Documentation
- OCI AI Services Overview
- Oracle Database 23ai Vector Search Guide
- Trustworthy AI Principles (Oracle / Industria)

## üßæ Glosario R√°pido
| T√©rmino | Definici√≥n Breve | Emoji |
|---------|------------------|-------|
| Embedding | Vector sem√°ntico denso de texto/imagen | üîó |
| Token | Unidad m√≠nima de entrada LLM | ‚úÇÔ∏è |
| Endpoint de Inferencia | API que expone predicciones | üöÄ |
| OCR | Extracci√≥n de texto en im√°genes | üîç |
| Key-Value Extraction | Pares estructurados (doc) | üßæ |
| Few-Shot | Pocos ejemplos en prompt | üéØ |
| In-Context Learning | Adaptaci√≥n sin reentrenar | üß© |
| Vanishing Gradient | Gradiente que se extingue | ü•Ä |
| T-Few | Fine-tuning eficiente | ‚öôÔ∏è |
| RDMA | Red de baja latencia | üöÑ |
| Loss Function | Mide error optimizaci√≥n | üìâ |

## ‚úÖ Checklist de Calidad para Nuevas Preguntas
Antes de agregar una nueva pregunta:
1. ¬øEl distractor m√°s plausible refleja un error conceptual com√∫n?
2. ¬øLa respuesta es inequ√≠voca con base en documentaci√≥n oficial?
3. ¬øEl escenario aporta aplicaci√≥n pr√°ctica (si corresponde)?
4. ¬øEvita ambig√ºedad terminol√≥gica (OCR vs Clasificaci√≥n Documentos)?
5. ¬øNo duplica innecesariamente otra pregunta sin variar el √°ngulo cognitivo?

## üèÅ Conclusi√≥n
Este documento extiende el material inicial proporcionando una base te√≥rica estructurada y criterios de mejora continua para el banco de preguntas. √ösalo junto con el `quiz.py` para un ciclo de aprendizaje activo: leer -> probar -> analizar fallos -> reforzar.

---
Fin de documentaci√≥n.
